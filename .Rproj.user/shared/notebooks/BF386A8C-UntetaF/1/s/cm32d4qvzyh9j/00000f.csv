"0","##### tokenizar en skip-gram"
"0","# en este caso cada token es un unigrama o un bigrama regular o un bigrama con espaciamiento"
"0","text_1997 %>%"
"0","  unnest_tokens(tbl = ., input = text, output = skipgram, token = ""skip_ngrams"", n = 2) %>%"
"0","  filter(!is.na(skipgram)) -> text_1997_skip"
"0","dim(text_1997_skip)"
"1","[1]"
"1"," 31144"
"1","     2"
"1","
"
"0","text_2001 %>%"
"0","  unnest_tokens(tbl = ., input = text, output = skipgram, token = ""skip_ngrams"", n = 2) %>%"
"0","  filter(!is.na(skipgram)) -> text_2001_skip"
"0","dim(text_2001_skip)"
"1","[1]"
"1"," 40728"
"1","     2"
"1","
"
"0","text_2005 %>%"
"0","  unnest_tokens(tbl = ., input = text, output = skipgram, token = ""skip_ngrams"", n = 2) %>%"
"0","  filter(!is.na(skipgram)) -> text_2005_skip"
"0","dim(text_2005_skip)"
"1","[1]"
"1"," 22792"
"1","     2"
"1","
"
"0","text_2008 %>%"
"0","  unnest_tokens(tbl = ., input = text, output = skipgram, token = ""skip_ngrams"", n = 2) %>%"
"0","  filter(!is.na(skipgram)) -> text_2008_skip"
"0","dim(text_2008_skip)"
"1","[1]"
"1"," 40861"
"1","     2"
"1","
"
"0","text_2010 %>%"
"0","  unnest_tokens(tbl = ., input = text, output = skipgram, token = ""skip_ngrams"", n = 2) %>%"
"0","  filter(!is.na(skipgram)) -> text_2010_skip"
"0","dim(text_2010_skip)"
"1","[1]"
"1"," 17871"
"1","     2"
"1","
"
